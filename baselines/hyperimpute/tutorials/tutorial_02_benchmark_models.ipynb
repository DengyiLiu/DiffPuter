{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f97fd9c",
   "metadata": {},
   "source": [
    "## Benchmark models using the missingness simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0d25e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "\n",
    "imputer = Imputers().get(\n",
    "    \"hyperimpute\",  # the name of the imputation method.\n",
    "    # The rest of the kwargs are specific to the method\n",
    "    # optimizer: str. The optimizer to use: simple, hyperband, bayesian\n",
    "    optimizer=\"hyperband\",\n",
    "    # classifier_seed: list. Model search pool for categorical columns.\n",
    "    classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "    # regression_seed: list. Model search pool for continuous columns.\n",
    "    regression_seed=[\n",
    "        \"linear_regression\",\n",
    "        \"catboost_regressor\",\n",
    "        \"xgboost_regressor\",\n",
    "        \"random_forest_regressor\",\n",
    "    ],\n",
    "    # class_threshold: int. how many max unique items must be in the column to be is associated with categorical\n",
    "    class_threshold=5,\n",
    "    # imputation_order: int. 0 - ascending, 1 - descending, 2 - random\n",
    "    imputation_order=2,\n",
    "    # n_inner_iter: int. number of imputation iterations\n",
    "    n_inner_iter=10,\n",
    "    # select_model_by_column: bool. If true, select a different model for each column. Else, it reuses the model chosen for the first column.\n",
    "    select_model_by_column=True,\n",
    "    # select_model_by_iteration: bool. If true, selects new models for each iteration. Else, it reuses the models chosen in the first iteration.\n",
    "    select_model_by_iteration=True,\n",
    "    # select_lazy: bool. If false, starts the optimizer on every column unless other restrictions apply. Else, if for the current iteration there is a trend(at least to columns of the same type got the same model from the optimizer), it reuses the same model class for all the columns without starting the optimizer.\n",
    "    select_lazy=True,\n",
    "    # select_patience: int. How many iterations without objective function improvement to wait.\n",
    "    select_patience=5,\n",
    ")\n",
    "\n",
    "# Load baseline dataset\n",
    "X, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "# Run benchmarks\n",
    "_ = compare_models(\n",
    "    name=\"example\",\n",
    "    evaluated_model=imputer,\n",
    "    X_raw=X,\n",
    "    ref_methods=[\"sklearn_ice\"],\n",
    "    scenarios=[\"MAR\"],\n",
    "    miss_pct=[0.3, 0.5],\n",
    "    n_iter=2,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ec28cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['median',\n",
       " 'softimpute',\n",
       " 'gain',\n",
       " 'sklearn_missforest',\n",
       " 'sinkhorn',\n",
       " 'miwae',\n",
       " 'most_frequent',\n",
       " 'mice',\n",
       " 'missforest',\n",
       " 'sklearn_ice',\n",
       " 'EM',\n",
       " 'hyperimpute',\n",
       " 'miracle',\n",
       " 'nop',\n",
       " 'ice',\n",
       " 'mean']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "methods_pool = imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6dff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         1.        ]\n",
      " [4.         5.         7.28479147 7.64277411]\n",
      " [3.         3.         9.         9.        ]\n",
      " [2.         2.         2.         2.        ]]\n",
      "gain      0    1         2         3\n",
      "0  1.0  1.0  1.000000  1.000000\n",
      "1  4.0  5.0  7.284791  7.642774\n",
      "2  3.0  3.0  9.000000  9.000000\n",
      "3  2.0  2.0  2.000000  2.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "X = pd.DataFrame([[1, 1, 1, 1], [4, 5, np.nan, np.nan], [3, 3, 9, 9], [2, 2, 2, 2]])\n",
    "\n",
    "method = \"gain\"\n",
    "\n",
    "plugin = Imputers().get(method)\n",
    "out = plugin.fit_transform(X.copy())\n",
    "print(out.values)\n",
    "print(method, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
